{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsFile = open('general/words.txt')\n",
    "words = []\n",
    "for word in wordsFile:\n",
    "    words.append(word.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dict with every category's nGram count distribution\n",
    "def generate_categories_dict():\n",
    "    categories = defaultdict()\n",
    "    for category in ['general', 'business', 'entertainment', 'politics', 'sport', 'tech']:\n",
    "        ngrams = []\n",
    "        for n in ['uni', 'bi', 'tri', 'four', 'five']:\n",
    "            if category == 'general':\n",
    "                filename = f'{category}/{n}grams.txt'\n",
    "            else:\n",
    "                filename = f'{category}/{category}_{n}grams.txt'\n",
    "\n",
    "            file = open(filename)\n",
    "\n",
    "            ngramVector = []\n",
    "            for l in file:\n",
    "                if n == 'uni':\n",
    "                    ngramVector.append(int(l))\n",
    "                else:\n",
    "                    ngramVector.append([int(x) for x in l.split()])\n",
    "            file.close()\n",
    "\n",
    "            # precomputing probabilities for unigrams\n",
    "            if n == 'uni':\n",
    "                uniSum = sum(ngramVector)\n",
    "                ngramVector = [x/uniSum for x in ngramVector]\n",
    "\n",
    "            ngrams.append(ngramVector)\n",
    "        categories[category] = ngrams\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probsUnigram(categories, category):\n",
    "    # Returns the category's unigram probabilities for every word\n",
    "    return categories[category][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probsNGram(evidence, categories, category, words):\n",
    "    # Returns the category's nGram probabilities for every nGrams\n",
    "    evidenceWords = evidence.split()\n",
    "    n = len(evidenceWords)\n",
    "    if n > 4:\n",
    "        n = 4\n",
    "        evidenceWords = evidenceWords[:n]\n",
    "    if any(word not in words for word in evidenceWords):\n",
    "        return [['', 0]]\n",
    "    corpus = categories[category][n]\n",
    "    counts = [[words[v[n]], v[n+1]] for v in corpus if [words.index(e) for e in evidenceWords] == v[:n]]\n",
    "    countsSum = sum([v[1] for v in counts])\n",
    "    probabilities = [[v[0], v[1]/countsSum] for v in counts]\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probsNGram(evidence, categories, category, words):\n",
    "    # Returns the category's nGram probabilities for every nGrams\n",
    "    evidenceWords = evidence.split()\n",
    "    n = len(evidenceWords)\n",
    "    if n > 4:\n",
    "        n = 4\n",
    "        evidenceWords = evidenceWords[-n:]\n",
    "    corpus = categories[category][n]\n",
    "    try:\n",
    "        counts = [[words[v[n]], v[n+1]] for v in corpus if [words.index(e) for e in evidenceWords] == v[:n]]\n",
    "    except ValueError:\n",
    "        return [['', 0]]\n",
    "    countsSum = sum([v[1] for v in counts])\n",
    "    probabilities = [[v[0], v[1]/countsSum] for v in counts]\n",
    "    return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigramProbability(word, probVector, words):\n",
    "    # Returns the category's unigram probability for a specific word\n",
    "    if word in words:\n",
    "        return probVector[words.index(word)]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nGramProbability(word, probVector):\n",
    "    # Returns the category's nGram probability for a specific nGram\n",
    "    prob = [v[1] for v in probVector if v[0] == word]\n",
    "    if len(prob) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixedProb(word, words, uniDist, nGramsDists, lambdas):\n",
    "    # Returs the mixed probability considering all nGrams\n",
    "    mixed = lambdas[0]*unigramProbability(word, uniDist, words)\n",
    "    for i in range(0, len(nGramsDists)):\n",
    "        mixed += lambdas[i+1]*nGramProbability(word, nGramsDists[i])\n",
    "    return mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNextWord(evidence, categories, category, probsUni, lambdas=[0.2]*5):\n",
    "    # Predicts the next word given a reference text\n",
    "    evidenceWords = evidence.split()\n",
    "    n = len(evidenceWords)\n",
    "    if n > 4:\n",
    "        n = 4\n",
    "        evidenceWords = evidenceWords[-n:]\n",
    "    sumRelevantLambdas = sum(lambdas[:n+1])\n",
    "    normLambda = [x/sumRelevantLambdas for x in lambdas[:n+1]]\n",
    "    nGramsDists = []\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        newEvidence = ' '.join(evidenceWords[-i:])\n",
    "        nGramsDists.append(probsNGram(newEvidence, categories, category, words))\n",
    "    \n",
    "    \n",
    "    probabilities = []\n",
    "    for word in words:\n",
    "        mixed = mixedProb(word, words, probsUni, nGramsDists, normLambda)\n",
    "        probabilities.append([word, mixed])\n",
    "    \n",
    "    \n",
    "    probabilities = sorted(probabilities, key = lambda x:-x[1])\n",
    "    return probabilities[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllPredictions(evidence, categories, category, probsUni, lambdas=[0.2]*5):\n",
    "    # Returns the 3 most probable fivegrams\n",
    "    recommendedWords = []\n",
    "    newEvidence = evidence\n",
    "    for i in range(0, 5):\n",
    "        newWord = predictNextWord(newEvidence, categories, category, \\\n",
    "                            probsUnigram(categories, category))\n",
    "\n",
    "        recommendedWords.append(newWord)\n",
    "        print(newWord)\n",
    "        newEvidence = ' '.join(newEvidence.split()[-3:] + [newWord])\n",
    "    return recommendedWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictCategory(evidence, categories, words):\n",
    "    categoriesV = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "    categoriesProbs = [0]*5\n",
    "    categoriesCounts = [0]*5\n",
    "    for word in evidence.split():\n",
    "        for i in range(1, len(categories)):\n",
    "            uniProbs = probsUnigram(categories, categoriesV[i-1])\n",
    "            wordProb = unigramProbability(word, uniProbs, words)\n",
    "            if wordProb != 0:\n",
    "                categoriesCounts[i-1] += 1\n",
    "                categoriesProbs[i-1] += wordProb\n",
    "    \n",
    "\n",
    "    for i in range(0, len(categoriesProbs)):\n",
    "        if categoriesCounts[i] != 0:\n",
    "            categoriesProbs[i] *= categoriesCounts[i]\n",
    "\n",
    "    return categoriesV[categoriesProbs.index(max(categoriesProbs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 3, 1]]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v for v in categories['sport'][1] if v[0] == 3 and v[1] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['football', 'set', 'crowd']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "predictNextWord('during the game the', categories, 'sport', probsUnigram(categories, 'sport'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "atmosphere\n",
      "in\n",
      "the\n",
      "city\n",
      "Wall time: 8min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the', 'atmosphere', 'in', 'the', 'city']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "getAllPredictions('game', categories, 'sport', probsUnigram(categories, 'sport'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'the and', 'the and of']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = ['the', 'and', 'of']\n",
    "[' '.join(v[:v.index(word)+1]) for word in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = generate_categories_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "three\n",
      "had\n",
      "been\n",
      "detained\n",
      "('business', ['the', 'three', 'had', 'been', 'detained'])\n",
      "not\n",
      "music\n",
      "we\n",
      "already\n",
      "have\n",
      "('entertainment', ['not', 'music', 'we', 'already', 'have'])\n",
      "the\n",
      "government\n",
      "was\n",
      "considering\n",
      "scrapping\n",
      "('politics', ['the', 'government', 'was', 'considering', 'scrapping'])\n",
      "i\n",
      "am\n",
      "in\n",
      "this\n",
      "situation\n",
      "('sport', ['i', 'am', 'in', 'this', 'situation'])\n",
      "the\n",
      "blocking\n",
      "was\n",
      "taking\n",
      "place\n",
      "('tech', ['the', 'blocking', 'was', 'taking', 'place'])\n"
     ]
    }
   ],
   "source": [
    "for cat in ['business', 'entertainment', 'politics', 'sport', 'tech']:\n",
    "    pred = getAllPredictions('it is unclear why', categories, cat, probsUnigram(categories, cat))\n",
    "    print((cat, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "latest\n",
      "in\n",
      "a\n",
      "series\n",
      "('business', ['the', 'latest', 'in', 'a', 'series'])\n",
      "the\n",
      "first\n",
      "time\n",
      "in\n",
      "the\n",
      "('entertainment', ['the', 'first', 'time', 'in', 'the'])\n",
      "the\n",
      "the\n",
      "original\n",
      "text\n",
      "was\n",
      "('politics', ['the', 'the', 'original', 'text', 'was'])\n",
      "a\n",
      "good\n",
      "performance\n",
      "he\n",
      "is\n",
      "('sport', ['a', 'good', 'performance', 'he', 'is'])\n",
      "the\n",
      "first\n",
      "time\n",
      "you\n",
      "can\n",
      "('tech', ['the', 'first', 'time', 'you', 'can'])\n"
     ]
    }
   ],
   "source": [
    "for cat in ['business', 'entertainment', 'politics', 'sport', 'tech']:\n",
    "    pred = getAllPredictions('the obvious conclusion is', categories, cat, probsUnigram(categories, cat))\n",
    "    print((cat, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
