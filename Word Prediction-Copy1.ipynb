{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsFile = open('general/words.txt')\n",
    "words = []\n",
    "for word in wordsFile:\n",
    "    words.append(word.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dict with every category's nGram count distribution\n",
    "def generate_categories_dict():\n",
    "    categories = defaultdict()\n",
    "    for category in ['general', 'business', 'entertainment', 'politics', 'sport', 'tech']:\n",
    "        ngrams = []\n",
    "        for n in ['uni', 'bi', 'tri', 'four', 'five']:\n",
    "            if category == 'general':\n",
    "                filename = f'{category}/{n}grams.txt'\n",
    "            else:\n",
    "                filename = f'{category}/{category}_{n}grams.txt'\n",
    "\n",
    "            file = open(filename)\n",
    "\n",
    "            ngramVector = []\n",
    "            for l in file:\n",
    "                if n == 'uni':\n",
    "                    ngramVector.append(int(l))\n",
    "                else:\n",
    "                    ngramVector.append([int(x) for x in l.split()])\n",
    "            file.close()\n",
    "\n",
    "            # precomputing probabilities for unigrams\n",
    "            if n == 'uni':\n",
    "                uniSum = sum(ngramVector)\n",
    "                ngramVector = [x/uniSum for x in ngramVector]\n",
    "\n",
    "            ngrams.append(ngramVector)\n",
    "        categories[category] = ngrams\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probsUnigram(categories, category):\n",
    "    # Returns the category's unigram probabilities for every word\n",
    "    return categories[category][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probsNGram(evidence, categories, category, words):\n",
    "    # Returns the category's nGram probabilities for every nGrams\n",
    "    evidenceWords = evidence.split()\n",
    "    n = len(evidenceWords)\n",
    "    if n > 4:\n",
    "        n = 4\n",
    "        evidenceWords = evidenceWords[:n]\n",
    "    if any(word not in words for word in evidenceWords):\n",
    "        return [['', 0]]\n",
    "    corpus = categories[category][n]\n",
    "    counts = [[words[v[n]], v[n+1]] for v in corpus if [words.index(e) for e in evidenceWords] == v[:n]]\n",
    "    countsSum = sum([v[1] for v in counts])\n",
    "    probabilities = [[v[0], v[1]/countsSum] for v in counts]\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probsNGram(evidence, categories, category, words):\n",
    "    # Returns the category's nGram probabilities for every nGrams\n",
    "    evidenceWords = evidence.split()\n",
    "    n = len(evidenceWords)\n",
    "    if n > 4:\n",
    "        n = 4\n",
    "        evidenceWords = evidenceWords[-n:]\n",
    "    corpus = categories[category][n]\n",
    "    try:\n",
    "        counts = [[words[v[n]], v[n+1]] for v in corpus if [words.index(e) for e in evidenceWords] == v[:n]]\n",
    "    except ValueError:\n",
    "        return [['', 0]]\n",
    "    countsSum = sum([v[1] for v in counts])\n",
    "    probabilities = [[v[0], v[1]/countsSum] for v in counts]\n",
    "    return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigramProbability(word, probVector, words):\n",
    "    # Returns the category's unigram probability for a specific word\n",
    "    if word in words:\n",
    "        return probVector[words.index(word)]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nGramProbability(word, probVector):\n",
    "    # Returns the category's nGram probability for a specific nGram\n",
    "    prob = [v[1] for v in probVector if v[0] == word]\n",
    "    if len(prob) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixedProb(word, words, uniDist, nGramsDists, lambdas):\n",
    "    # Returs the mixed probability considering all nGrams\n",
    "    mixed = lambdas[0]*unigramProbability(word, uniDist, words)\n",
    "    for i in range(0, len(nGramsDists)):\n",
    "        mixed += lambdas[i+1]*nGramProbability(word, nGramsDists[i])\n",
    "    return mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNextWord(evidence, categories, category, probsUni, lambdas=[0.2]*5):\n",
    "    # Predicts the next word given a reference text\n",
    "    evidenceWords = evidence.split()\n",
    "    n = len(evidenceWords)\n",
    "    if n > 4:\n",
    "        n = 4\n",
    "        evidenceWords = evidenceWords[-n:]\n",
    "    sumRelevantLambdas = sum(lambdas[:n+1])\n",
    "    normLambda = [x/sumRelevantLambdas for x in lambdas[:n+1]]\n",
    "    nGramsDists = []\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        newEvidence = ' '.join(evidenceWords[-i:])\n",
    "        nGramsDists.append(probsNGram(newEvidence, categories, category, words))\n",
    "    \n",
    "    \n",
    "    probabilities = []\n",
    "    for word in words:\n",
    "        mixed = mixedProb(word, words, probsUni, nGramsDists, normLambda)\n",
    "        probabilities.append([word, mixed])\n",
    "    \n",
    "    \n",
    "    probabilities = sorted(probabilities, key = lambda x:-x[1])\n",
    "    return probabilities[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllPredictions(evidence, categories, category, probsUni, lambdas=[0.2]*5):\n",
    "    # Returns the 3 most probable fivegrams\n",
    "    recommendedWords = []\n",
    "    newEvidence = evidence\n",
    "    for i in range(0, 5):\n",
    "        newWord = predictNextWord(newEvidence, categories, category, \\\n",
    "                            probsUnigram(categories, category))\n",
    "\n",
    "        recommendedWords.append(newWord)\n",
    "        print(newWord)\n",
    "        newEvidence = ' '.join(newEvidence.split()[-3:] + [newWord])\n",
    "    return recommendedWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictCategory(evidence, categories, words):\n",
    "    categoriesV = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "    categoriesProbs = [0]*5\n",
    "    categoriesCounts = [0]*5\n",
    "    for word in evidence.split():\n",
    "        for i in range(1, len(categories)):\n",
    "            uniProbs = probsUnigram(categories, categoriesV[i-1])\n",
    "            wordProb = unigramProbability(word, uniProbs, words)\n",
    "            if wordProb != 0:\n",
    "                categoriesCounts[i-1] += 1\n",
    "                categoriesProbs[i-1] += wordProb\n",
    "    \n",
    "\n",
    "    for i in range(0, len(categoriesProbs)):\n",
    "        if categoriesCounts[i] != 0:\n",
    "            categoriesProbs[i] *= categoriesCounts[i]\n",
    "\n",
    "    return categoriesV[categoriesProbs.index(max(categoriesProbs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = generate_categories_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "budget\n",
      "sinners\n",
      "despite\n",
      "having\n",
      "repeatedly\n",
      "('business', ['budget', 'sinners', 'despite', 'having', 'repeatedly'])\n",
      "they\n",
      "are\n",
      "wide\n",
      "open\n",
      "to\n",
      "('entertainment', ['they', 'are', 'wide', 'open', 'to'])\n",
      "the\n",
      "eu\n",
      "benefits\n",
      "germany\n",
      "but\n",
      "('politics', ['the', 'eu', 'benefits', 'germany', 'but'])\n",
      "i\n",
      "would\n",
      "have\n",
      "a\n",
      "lot\n",
      "('sport', ['i', 'would', 'have', 'a', 'lot'])\n",
      "the\n",
      "line\n",
      "between\n",
      "home\n",
      "entertainment\n",
      "('tech', ['the', 'line', 'between', 'home', 'entertainment'])\n"
     ]
    }
   ],
   "source": [
    "for cat in ['business', 'entertainment', 'politics', 'sport', 'tech']:\n",
    "    pred = getAllPredictions('the fact is that', categories, cat, probsUnigram(categories, cat))\n",
    "    print((cat, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\n",
      "a\n",
      "time\n",
      "when\n",
      "weak\n",
      "('business', ['of', 'a', 'time', 'when', 'weak'])\n",
      "in\n",
      "the\n",
      "community\n",
      "50\n",
      "cent\n",
      "('entertainment', ['in', 'the', 'community', '50', 'cent'])\n",
      "of\n",
      "immigration\n",
      "problems\n",
      "lib\n",
      "dem\n",
      "('politics', ['of', 'immigration', 'problems', 'lib', 'dem'])\n",
      "of\n",
      "several\n",
      "players\n",
      "on\n",
      "the\n",
      "('sport', ['of', 'several', 'players', 'on', 'the'])\n",
      "of\n",
      "him\n",
      "the\n",
      "organisation\n",
      "said\n",
      "('tech', ['of', 'him', 'the', 'organisation', 'said'])\n"
     ]
    }
   ],
   "source": [
    "for cat in ['business', 'entertainment', 'politics', 'sport', 'tech']:\n",
    "    pred = getAllPredictions('this is an example', categories, cat, probsUnigram(categories, cat))\n",
    "    print((cat, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
